{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.book import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Pierre',\n",
       " 'Vinken',\n",
       " ',',\n",
       " '61',\n",
       " 'years',\n",
       " 'old',\n",
       " ',',\n",
       " 'will',\n",
       " 'join',\n",
       " 'the',\n",
       " 'board',\n",
       " 'as',\n",
       " 'a',\n",
       " 'nonexecutive',\n",
       " 'director',\n",
       " 'Nov.',\n",
       " '29',\n",
       " '.',\n",
       " 'Mr.',\n",
       " 'Vinken',\n",
       " 'is',\n",
       " 'chairman',\n",
       " 'of',\n",
       " 'Elsevier',\n",
       " 'N.V.',\n",
       " ',',\n",
       " 'the',\n",
       " 'Dutch',\n",
       " 'publishing',\n",
       " 'group',\n",
       " '.',\n",
       " 'Rudolph',\n",
       " 'Agnew',\n",
       " ',',\n",
       " '55',\n",
       " 'years',\n",
       " 'old',\n",
       " 'and',\n",
       " 'former',\n",
       " 'chairman',\n",
       " 'of',\n",
       " 'Consolidated',\n",
       " 'Gold',\n",
       " 'Fields',\n",
       " 'PLC',\n",
       " ',',\n",
       " 'was',\n",
       " 'named',\n",
       " '*-1',\n",
       " 'a',\n",
       " 'nonexecutive',\n",
       " 'director',\n",
       " 'of',\n",
       " 'this',\n",
       " 'British',\n",
       " 'industrial',\n",
       " 'conglomerate',\n",
       " '.',\n",
       " 'A',\n",
       " 'form',\n",
       " 'of',\n",
       " 'asbestos',\n",
       " 'once',\n",
       " 'used',\n",
       " '*',\n",
       " '*',\n",
       " 'to',\n",
       " 'make',\n",
       " 'Kent',\n",
       " 'cigarette',\n",
       " 'filters',\n",
       " 'has',\n",
       " 'caused',\n",
       " 'a',\n",
       " 'high',\n",
       " 'percentage',\n",
       " 'of',\n",
       " 'cancer',\n",
       " 'deaths',\n",
       " 'among',\n",
       " 'a',\n",
       " 'group',\n",
       " 'of',\n",
       " 'workers',\n",
       " 'exposed',\n",
       " '*',\n",
       " 'to',\n",
       " 'it',\n",
       " 'more',\n",
       " 'than',\n",
       " '30',\n",
       " 'years',\n",
       " 'ago',\n",
       " ',',\n",
       " 'researchers',\n",
       " 'reported',\n",
       " '0',\n",
       " '*T*-1',\n",
       " '.',\n",
       " 'The',\n",
       " 'asbestos',\n",
       " 'fiber',\n",
       " ',',\n",
       " 'crocidolite',\n",
       " ',',\n",
       " 'is',\n",
       " 'unusually',\n",
       " 'resilient',\n",
       " 'once',\n",
       " 'it',\n",
       " 'enters',\n",
       " 'the',\n",
       " 'lungs',\n",
       " ',',\n",
       " 'with',\n",
       " 'even',\n",
       " 'brief',\n",
       " 'exposures',\n",
       " 'to',\n",
       " 'it',\n",
       " 'causing',\n",
       " 'symptoms',\n",
       " 'that',\n",
       " '*T*-1',\n",
       " 'show',\n",
       " 'up',\n",
       " 'decades',\n",
       " 'later',\n",
       " ',',\n",
       " 'researchers',\n",
       " 'said',\n",
       " '0',\n",
       " '*T*-2',\n",
       " '.',\n",
       " 'Lorillard',\n",
       " 'Inc.',\n",
       " ',',\n",
       " 'the',\n",
       " 'unit',\n",
       " 'of',\n",
       " 'New',\n",
       " 'York-based',\n",
       " 'Loews',\n",
       " 'Corp.',\n",
       " 'that',\n",
       " '*T*-2',\n",
       " 'makes',\n",
       " 'Kent',\n",
       " 'cigarettes',\n",
       " ',',\n",
       " 'stopped',\n",
       " 'using',\n",
       " 'crocidolite',\n",
       " 'in',\n",
       " 'its',\n",
       " 'Micronite',\n",
       " 'cigarette',\n",
       " 'filters',\n",
       " 'in',\n",
       " '1956',\n",
       " '.',\n",
       " 'Although',\n",
       " 'preliminary',\n",
       " 'findings',\n",
       " 'were',\n",
       " 'reported',\n",
       " '*-2',\n",
       " 'more',\n",
       " 'than',\n",
       " 'a',\n",
       " 'year',\n",
       " 'ago',\n",
       " ',',\n",
       " 'the',\n",
       " 'latest',\n",
       " 'results',\n",
       " 'appear',\n",
       " 'in',\n",
       " 'today',\n",
       " \"'s\",\n",
       " 'New',\n",
       " 'England',\n",
       " 'Journal',\n",
       " 'of',\n",
       " 'Medicine',\n",
       " ',',\n",
       " 'a',\n",
       " 'forum',\n",
       " 'likely',\n",
       " '*',\n",
       " 'to',\n",
       " 'bring',\n",
       " 'new',\n",
       " 'attention',\n",
       " 'to',\n",
       " 'the',\n",
       " 'problem',\n",
       " '.',\n",
       " 'A',\n",
       " 'Lorillard',\n",
       " 'spokewoman',\n",
       " 'said',\n",
       " ',',\n",
       " '``',\n",
       " 'This',\n",
       " 'is',\n",
       " 'an',\n",
       " 'old',\n",
       " 'story',\n",
       " '.',\n",
       " 'We',\n",
       " \"'re\",\n",
       " 'talking',\n",
       " 'about',\n",
       " 'years',\n",
       " 'ago',\n",
       " 'before',\n",
       " 'anyone',\n",
       " 'heard',\n",
       " 'of',\n",
       " 'asbestos',\n",
       " 'having',\n",
       " 'any',\n",
       " 'questionable',\n",
       " 'properties',\n",
       " '.',\n",
       " 'There',\n",
       " 'is',\n",
       " 'no',\n",
       " 'asbestos',\n",
       " 'in',\n",
       " 'our',\n",
       " 'products',\n",
       " 'now',\n",
       " '.',\n",
       " \"''\",\n",
       " 'Neither',\n",
       " 'Lorillard',\n",
       " 'nor',\n",
       " 'the',\n",
       " 'researchers',\n",
       " 'who',\n",
       " '*T*-3',\n",
       " 'studied',\n",
       " 'the',\n",
       " 'workers',\n",
       " 'were',\n",
       " 'aware',\n",
       " 'of',\n",
       " 'any',\n",
       " 'research',\n",
       " 'on',\n",
       " 'smokers',\n",
       " 'of',\n",
       " 'the',\n",
       " 'Kent',\n",
       " 'cigarettes',\n",
       " '.',\n",
       " '``',\n",
       " 'We',\n",
       " 'have',\n",
       " 'no',\n",
       " 'useful',\n",
       " 'information',\n",
       " 'on',\n",
       " 'whether',\n",
       " 'users',\n",
       " 'are',\n",
       " 'at',\n",
       " 'risk',\n",
       " ',',\n",
       " \"''\",\n",
       " 'said',\n",
       " '*T*-1',\n",
       " 'James',\n",
       " 'A.',\n",
       " 'Talcott',\n",
       " 'of',\n",
       " 'Boston',\n",
       " \"'s\",\n",
       " 'Dana-Farber',\n",
       " 'Cancer',\n",
       " 'Institute',\n",
       " '.',\n",
       " 'Dr.',\n",
       " 'Talcott',\n",
       " 'led',\n",
       " 'a',\n",
       " 'team',\n",
       " 'of',\n",
       " 'researchers',\n",
       " 'from',\n",
       " 'the',\n",
       " 'National',\n",
       " 'Cancer',\n",
       " 'Institute',\n",
       " 'and',\n",
       " 'the',\n",
       " 'medical',\n",
       " 'schools',\n",
       " 'of',\n",
       " 'Harvard',\n",
       " 'University',\n",
       " 'and',\n",
       " 'Boston',\n",
       " 'University',\n",
       " '.',\n",
       " 'The',\n",
       " 'Lorillard',\n",
       " 'spokeswoman',\n",
       " 'said',\n",
       " '0',\n",
       " 'asbestos',\n",
       " 'was',\n",
       " 'used',\n",
       " '*-1',\n",
       " 'in',\n",
       " '``',\n",
       " 'very',\n",
       " 'modest',\n",
       " 'amounts',\n",
       " \"''\",\n",
       " 'in',\n",
       " '*',\n",
       " 'making',\n",
       " 'paper',\n",
       " 'for',\n",
       " 'the',\n",
       " 'filters',\n",
       " 'in',\n",
       " 'the',\n",
       " 'early',\n",
       " '1950s',\n",
       " 'and',\n",
       " 'replaced',\n",
       " '*-1',\n",
       " 'with',\n",
       " 'a',\n",
       " 'different',\n",
       " 'type',\n",
       " 'of',\n",
       " 'filter',\n",
       " 'in',\n",
       " '1956',\n",
       " '.',\n",
       " 'From',\n",
       " '1953',\n",
       " 'to',\n",
       " '1955',\n",
       " ',',\n",
       " '9.8',\n",
       " 'billion',\n",
       " 'Kent',\n",
       " 'cigarettes',\n",
       " 'with',\n",
       " 'the',\n",
       " 'filters',\n",
       " 'were',\n",
       " 'sold',\n",
       " '*-3',\n",
       " ',',\n",
       " 'the',\n",
       " 'company',\n",
       " 'said',\n",
       " '0',\n",
       " '*T*-1',\n",
       " '.',\n",
       " 'Among',\n",
       " '33',\n",
       " 'men',\n",
       " 'who',\n",
       " '*T*-4',\n",
       " 'worked',\n",
       " 'closely',\n",
       " 'with',\n",
       " 'the',\n",
       " 'substance',\n",
       " ',',\n",
       " '28',\n",
       " '*ICH*-1',\n",
       " 'have',\n",
       " 'died',\n",
       " '--',\n",
       " 'more',\n",
       " 'than',\n",
       " 'three',\n",
       " 'times',\n",
       " 'the',\n",
       " 'expected',\n",
       " 'number',\n",
       " '.',\n",
       " 'Four',\n",
       " 'of',\n",
       " 'the',\n",
       " 'five',\n",
       " 'surviving',\n",
       " 'workers',\n",
       " 'have',\n",
       " 'asbestos-related',\n",
       " 'diseases',\n",
       " ',',\n",
       " 'including',\n",
       " 'three',\n",
       " 'with',\n",
       " 'recently',\n",
       " 'diagnosed',\n",
       " 'cancer',\n",
       " '.',\n",
       " 'The',\n",
       " 'total',\n",
       " 'of',\n",
       " '18',\n",
       " 'deaths',\n",
       " 'from',\n",
       " 'malignant',\n",
       " 'mesothelioma',\n",
       " ',',\n",
       " 'lung',\n",
       " 'cancer',\n",
       " 'and',\n",
       " 'asbestosis',\n",
       " 'was',\n",
       " 'far',\n",
       " 'higher',\n",
       " 'than',\n",
       " '*',\n",
       " 'expected',\n",
       " '*?*',\n",
       " ',',\n",
       " 'the',\n",
       " 'researchers',\n",
       " 'said',\n",
       " '0',\n",
       " '*T*-1',\n",
       " '.',\n",
       " '``',\n",
       " 'The',\n",
       " 'morbidity',\n",
       " 'rate',\n",
       " 'is',\n",
       " 'a',\n",
       " 'striking',\n",
       " 'finding',\n",
       " 'among',\n",
       " 'those',\n",
       " 'of',\n",
       " 'us',\n",
       " 'who',\n",
       " '*T*-5',\n",
       " 'study',\n",
       " 'asbestos-related',\n",
       " 'diseases',\n",
       " ',',\n",
       " \"''\",\n",
       " 'said',\n",
       " '*T*-1',\n",
       " 'Dr.',\n",
       " 'Talcott',\n",
       " '.',\n",
       " 'The',\n",
       " 'percentage',\n",
       " 'of',\n",
       " 'lung',\n",
       " 'cancer',\n",
       " 'deaths',\n",
       " 'among',\n",
       " 'the',\n",
       " 'workers',\n",
       " 'at',\n",
       " 'the',\n",
       " 'West',\n",
       " 'Groton',\n",
       " ',',\n",
       " 'Mass.',\n",
       " ',',\n",
       " 'paper',\n",
       " 'factory',\n",
       " 'appears',\n",
       " '*-1',\n",
       " 'to',\n",
       " 'be',\n",
       " 'the',\n",
       " 'highest',\n",
       " 'for',\n",
       " 'any',\n",
       " 'asbestos',\n",
       " 'workers',\n",
       " 'studied',\n",
       " '*',\n",
       " 'in',\n",
       " 'Western',\n",
       " 'industrialized',\n",
       " 'countries',\n",
       " ',',\n",
       " 'he',\n",
       " 'said',\n",
       " '0',\n",
       " '*T*-2',\n",
       " '.',\n",
       " 'The',\n",
       " 'plant',\n",
       " ',',\n",
       " 'which',\n",
       " '*T*-1',\n",
       " 'is',\n",
       " 'owned',\n",
       " '*-4',\n",
       " 'by',\n",
       " 'Hollingsworth',\n",
       " '&',\n",
       " 'Vose',\n",
       " 'Co.',\n",
       " ',',\n",
       " 'was',\n",
       " 'under',\n",
       " 'contract',\n",
       " '*ICH*-2',\n",
       " 'with',\n",
       " 'Lorillard',\n",
       " '*',\n",
       " 'to',\n",
       " 'make',\n",
       " 'the',\n",
       " 'cigarette',\n",
       " 'filters',\n",
       " '.',\n",
       " 'The',\n",
       " 'finding',\n",
       " 'probably',\n",
       " 'will',\n",
       " 'support',\n",
       " 'those',\n",
       " 'who',\n",
       " '*T*-6',\n",
       " 'argue',\n",
       " 'that',\n",
       " 'the',\n",
       " 'U.S.',\n",
       " 'should',\n",
       " 'regulate',\n",
       " 'the',\n",
       " 'class',\n",
       " 'of',\n",
       " 'asbestos',\n",
       " 'including',\n",
       " 'crocidolite',\n",
       " 'more',\n",
       " 'stringently',\n",
       " 'than',\n",
       " 'the',\n",
       " 'common',\n",
       " 'kind',\n",
       " 'of',\n",
       " 'asbestos',\n",
       " ',',\n",
       " 'chrysotile',\n",
       " ',',\n",
       " 'found',\n",
       " '*',\n",
       " 'in',\n",
       " 'most',\n",
       " 'schools',\n",
       " 'and',\n",
       " 'other',\n",
       " 'buildings',\n",
       " ',',\n",
       " 'Dr.',\n",
       " 'Talcott',\n",
       " 'said',\n",
       " '0',\n",
       " '*T*-1',\n",
       " '.',\n",
       " 'The',\n",
       " 'U.S.',\n",
       " 'is',\n",
       " 'one',\n",
       " 'of',\n",
       " 'the',\n",
       " 'few',\n",
       " 'industrialized',\n",
       " 'nations',\n",
       " 'that',\n",
       " '*T*-7',\n",
       " 'does',\n",
       " \"n't\",\n",
       " 'have',\n",
       " 'a',\n",
       " 'higher',\n",
       " 'standard',\n",
       " 'of',\n",
       " 'regulation',\n",
       " 'for',\n",
       " 'the',\n",
       " 'smooth',\n",
       " ',',\n",
       " 'needle-like',\n",
       " 'fibers',\n",
       " 'such',\n",
       " 'as',\n",
       " 'crocidolite',\n",
       " 'that',\n",
       " '*T*-1',\n",
       " 'are',\n",
       " 'classified',\n",
       " '*-5',\n",
       " 'as',\n",
       " 'amphobiles',\n",
       " ',',\n",
       " 'according',\n",
       " 'to',\n",
       " 'Brooke',\n",
       " 'T.',\n",
       " 'Mossman',\n",
       " ',',\n",
       " 'a',\n",
       " 'professor',\n",
       " 'of',\n",
       " 'pathlogy',\n",
       " 'at',\n",
       " 'the',\n",
       " 'University',\n",
       " 'of',\n",
       " 'Vermont',\n",
       " 'College',\n",
       " 'of',\n",
       " 'Medicine',\n",
       " '.',\n",
       " 'More',\n",
       " 'common',\n",
       " 'chrysotile',\n",
       " 'fibers',\n",
       " 'are',\n",
       " 'curly',\n",
       " 'and',\n",
       " 'are',\n",
       " 'more',\n",
       " 'easily',\n",
       " 'rejected',\n",
       " '*-1',\n",
       " 'by',\n",
       " 'the',\n",
       " 'body',\n",
       " ',',\n",
       " 'Dr.',\n",
       " 'Mossman',\n",
       " 'explained',\n",
       " '0',\n",
       " '*T*-2',\n",
       " '.',\n",
       " 'In',\n",
       " 'July',\n",
       " ',',\n",
       " 'the',\n",
       " 'Environmental',\n",
       " 'Protection',\n",
       " 'Agency',\n",
       " 'imposed',\n",
       " 'a',\n",
       " 'gradual',\n",
       " 'ban',\n",
       " 'on',\n",
       " 'virtually',\n",
       " 'all',\n",
       " 'uses',\n",
       " 'of',\n",
       " 'asbestos',\n",
       " '.',\n",
       " 'By',\n",
       " '1997',\n",
       " ',',\n",
       " 'almost',\n",
       " 'all',\n",
       " 'remaining',\n",
       " 'uses',\n",
       " 'of',\n",
       " 'cancer-causing',\n",
       " 'asbestos',\n",
       " 'will',\n",
       " 'be',\n",
       " 'outlawed',\n",
       " '*-6',\n",
       " '.',\n",
       " 'About',\n",
       " '160',\n",
       " 'workers',\n",
       " 'at',\n",
       " 'a',\n",
       " 'factory',\n",
       " 'that',\n",
       " '*T*-8',\n",
       " 'made',\n",
       " 'paper',\n",
       " 'for',\n",
       " 'the',\n",
       " 'Kent',\n",
       " 'filters',\n",
       " 'were',\n",
       " 'exposed',\n",
       " '*-7',\n",
       " 'to',\n",
       " 'asbestos',\n",
       " 'in',\n",
       " 'the',\n",
       " '1950s',\n",
       " '.',\n",
       " 'Areas',\n",
       " 'of',\n",
       " 'the',\n",
       " 'factory',\n",
       " '*ICH*-2',\n",
       " 'were',\n",
       " 'particularly',\n",
       " 'dusty',\n",
       " 'where',\n",
       " 'the',\n",
       " 'crocidolite',\n",
       " 'was',\n",
       " 'used',\n",
       " '*-8',\n",
       " '*T*-1',\n",
       " '.',\n",
       " 'Workers',\n",
       " 'dumped',\n",
       " 'large',\n",
       " 'burlap',\n",
       " 'sacks',\n",
       " 'of',\n",
       " 'the',\n",
       " 'imported',\n",
       " 'material',\n",
       " 'into',\n",
       " 'a',\n",
       " 'huge',\n",
       " 'bin',\n",
       " ',',\n",
       " 'poured',\n",
       " 'in',\n",
       " 'cotton',\n",
       " 'and',\n",
       " 'acetate',\n",
       " 'fibers',\n",
       " 'and',\n",
       " 'mechanically',\n",
       " 'mixed',\n",
       " 'the',\n",
       " 'dry',\n",
       " 'fibers',\n",
       " 'in',\n",
       " 'a',\n",
       " 'process',\n",
       " 'used',\n",
       " '*',\n",
       " '*',\n",
       " 'to',\n",
       " 'make',\n",
       " 'filters',\n",
       " '.',\n",
       " 'Workers',\n",
       " 'described',\n",
       " '``',\n",
       " 'clouds',\n",
       " 'of',\n",
       " 'blue',\n",
       " 'dust',\n",
       " \"''\",\n",
       " 'that',\n",
       " '*T*-1',\n",
       " 'hung',\n",
       " 'over',\n",
       " 'parts',\n",
       " 'of',\n",
       " 'the',\n",
       " 'factory',\n",
       " ',',\n",
       " 'even',\n",
       " 'though',\n",
       " 'exhaust',\n",
       " 'fans',\n",
       " 'ventilated',\n",
       " 'the',\n",
       " 'area',\n",
       " '.',\n",
       " '``',\n",
       " 'There',\n",
       " \"'s\",\n",
       " 'no',\n",
       " 'question',\n",
       " 'that',\n",
       " 'some',\n",
       " 'of',\n",
       " 'those',\n",
       " 'workers',\n",
       " 'and',\n",
       " 'managers',\n",
       " 'contracted',\n",
       " 'asbestos-related',\n",
       " 'diseases',\n",
       " ',',\n",
       " \"''\",\n",
       " 'said',\n",
       " '*T*-1',\n",
       " 'Darrell',\n",
       " 'Phillips',\n",
       " ',',\n",
       " 'vice',\n",
       " 'president',\n",
       " 'of',\n",
       " 'human',\n",
       " 'resources',\n",
       " 'for',\n",
       " 'Hollingsworth',\n",
       " '&',\n",
       " 'Vose',\n",
       " '.',\n",
       " '``',\n",
       " 'But',\n",
       " 'you',\n",
       " 'have',\n",
       " '*-1',\n",
       " 'to',\n",
       " 'recognize',\n",
       " 'that',\n",
       " 'these',\n",
       " 'events',\n",
       " 'took',\n",
       " 'place',\n",
       " '35',\n",
       " 'years',\n",
       " 'ago',\n",
       " '.',\n",
       " 'It',\n",
       " 'has',\n",
       " 'no',\n",
       " 'bearing',\n",
       " 'on',\n",
       " 'our',\n",
       " 'work',\n",
       " 'force',\n",
       " 'today',\n",
       " '.',\n",
       " 'Yields',\n",
       " 'on',\n",
       " 'money-market',\n",
       " 'mutual',\n",
       " 'funds',\n",
       " 'continued',\n",
       " '*-1',\n",
       " 'to',\n",
       " 'slide',\n",
       " ',',\n",
       " 'amid',\n",
       " 'signs',\n",
       " 'that',\n",
       " 'portfolio',\n",
       " 'managers',\n",
       " 'expect',\n",
       " 'further',\n",
       " 'declines',\n",
       " 'in',\n",
       " 'interest',\n",
       " 'rates',\n",
       " '.',\n",
       " 'The',\n",
       " 'average',\n",
       " 'seven-day',\n",
       " 'compound',\n",
       " 'yield',\n",
       " 'of',\n",
       " 'the',\n",
       " '400',\n",
       " 'taxable',\n",
       " 'funds',\n",
       " 'tracked',\n",
       " '*',\n",
       " 'by',\n",
       " 'IBC',\n",
       " \"'s\",\n",
       " 'Money',\n",
       " 'Fund',\n",
       " 'Report',\n",
       " 'eased',\n",
       " 'a',\n",
       " 'fraction',\n",
       " 'of',\n",
       " 'a',\n",
       " 'percentage',\n",
       " 'point',\n",
       " 'to',\n",
       " '8.45',\n",
       " '%',\n",
       " 'from',\n",
       " '8.47',\n",
       " '%',\n",
       " 'for',\n",
       " 'the',\n",
       " 'week',\n",
       " 'ended',\n",
       " 'Tuesday',\n",
       " '.',\n",
       " 'Compound',\n",
       " 'yields',\n",
       " 'assume',\n",
       " 'reinvestment',\n",
       " 'of',\n",
       " 'dividends',\n",
       " 'and',\n",
       " 'that',\n",
       " 'the',\n",
       " 'current',\n",
       " 'yield',\n",
       " 'continues',\n",
       " 'for',\n",
       " 'a',\n",
       " 'year',\n",
       " '.',\n",
       " 'Average',\n",
       " 'maturity',\n",
       " 'of',\n",
       " 'the',\n",
       " 'funds',\n",
       " \"'\",\n",
       " 'investments',\n",
       " 'lengthened',\n",
       " 'by',\n",
       " 'a',\n",
       " 'day',\n",
       " 'to',\n",
       " '41',\n",
       " 'days',\n",
       " ',',\n",
       " 'the',\n",
       " 'longest',\n",
       " 'since',\n",
       " 'early',\n",
       " 'August',\n",
       " ',',\n",
       " 'according',\n",
       " 'to',\n",
       " 'Donoghue',\n",
       " \"'s\",\n",
       " '.',\n",
       " 'Longer',\n",
       " 'maturities',\n",
       " 'are',\n",
       " 'thought',\n",
       " '*-1',\n",
       " 'to',\n",
       " 'indicate',\n",
       " 'declining',\n",
       " 'interest',\n",
       " 'rates',\n",
       " 'because',\n",
       " 'they',\n",
       " 'permit',\n",
       " 'portfolio',\n",
       " 'managers',\n",
       " 'to',\n",
       " 'retain',\n",
       " 'relatively',\n",
       " 'higher',\n",
       " 'rates',\n",
       " 'for',\n",
       " 'a',\n",
       " 'longer',\n",
       " 'period',\n",
       " '.',\n",
       " 'Shorter',\n",
       " 'maturities',\n",
       " 'are',\n",
       " 'considered',\n",
       " '*-9',\n",
       " 'a',\n",
       " 'sign',\n",
       " 'of',\n",
       " 'rising',\n",
       " 'rates',\n",
       " 'because',\n",
       " 'portfolio',\n",
       " 'managers',\n",
       " 'can',\n",
       " 'capture',\n",
       " 'higher',\n",
       " 'rates',\n",
       " 'sooner',\n",
       " '.',\n",
       " 'The',\n",
       " 'average',\n",
       " 'maturity',\n",
       " 'for',\n",
       " 'funds',\n",
       " 'open',\n",
       " 'only',\n",
       " 'to',\n",
       " 'institutions',\n",
       " ',',\n",
       " 'considered',\n",
       " 'by',\n",
       " 'some',\n",
       " '*',\n",
       " 'to',\n",
       " ...]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#text7.tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({',': 4885, 'the': 4045, '.': 3828, 'of': 2319, 'to': 2164, 'a': 1878, 'in': 1572, 'and': 1511, '*-1': 1123, '0': 1099, ...})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text7.vocab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 19 of 19 matches:\n",
      " meeting -- Boca in February . South Korea registered a trade deficit of $ 101 \n",
      "is year , * casting a cloud on South Korea 's export-oriented economy . Exports\n",
      " , up 20 % from last October . South Korea 's economic boom , which *T*-12 bega\n",
      " Despite the gloomy forecast , South Korea has recorded a trade surplus of $ 71\n",
      "0 it opened a plant *ICH*-3 in South Korea 0 *T*-2 to manufacture control devic\n",
      "demand for control products in South Korea , the company said 0 *T*-1 . The pla\n",
      " its trade diplomacy , removed South Korea , Taiwan and Saudi Arabia from a lis\n",
      "ucts there . Mrs. Hills lauded South Korea for *-1 creating an intellectual-pro\n",
      "ted the improvements made * by South Korea , Taiwan and Saudi Arabia . `` What \n",
      "to foreign investors , such as South Korea , some specialists say 0 *T*-1 . But\n",
      "*-1 to ban on-campus smoking . South Korea has different concerns . In Seoul , \n",
      "ertising imported cigarettes . South Korea has opened its market to foreign cig\n",
      "oal prices . In happier news , South Korea , in *-1 establishing diplomatic tie\n",
      "nto the region . In Taiwan and South Korea , rising wages are forcing manufactu\n",
      ", Australia , Canada , Japan , South Korea and New Zealand as well as the six m\n",
      "ssible U.S. troop reduction in South Korea . Many Asians regard a U.S. presence\n",
      " . For their part , Taiwan and South Korea are expected *-1 to step up their ow\n",
      "rs from Hong Kong , Taiwan and South Korea may be injuring a domestic industry \n",
      "aiwan , $ 400 million *U* from South Korea and $ 125 million *U* from Hong Kong\n"
     ]
    }
   ],
   "source": [
    "text7.concordance('Korea')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100676"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['!',\n",
       " '#',\n",
       " '$',\n",
       " '%',\n",
       " '&',\n",
       " \"'\",\n",
       " \"''\",\n",
       " \"'30s\",\n",
       " \"'40s\",\n",
       " \"'50s\",\n",
       " \"'80s\",\n",
       " \"'82\",\n",
       " \"'86\",\n",
       " \"'S\",\n",
       " \"'d\",\n",
       " \"'ll\",\n",
       " \"'m\",\n",
       " \"'re\",\n",
       " \"'s\",\n",
       " \"'ve\",\n",
       " '*',\n",
       " '*-1',\n",
       " '*-10',\n",
       " '*-100',\n",
       " '*-101',\n",
       " '*-102',\n",
       " '*-103',\n",
       " '*-104',\n",
       " '*-105',\n",
       " '*-106',\n",
       " '*-107',\n",
       " '*-108',\n",
       " '*-109',\n",
       " '*-11',\n",
       " '*-110',\n",
       " '*-111',\n",
       " '*-112',\n",
       " '*-113',\n",
       " '*-114',\n",
       " '*-115',\n",
       " '*-116',\n",
       " '*-117',\n",
       " '*-118',\n",
       " '*-119',\n",
       " '*-12',\n",
       " '*-120',\n",
       " '*-121',\n",
       " '*-122',\n",
       " '*-123',\n",
       " '*-124',\n",
       " '*-125',\n",
       " '*-126',\n",
       " '*-127',\n",
       " '*-128',\n",
       " '*-129',\n",
       " '*-13',\n",
       " '*-130',\n",
       " '*-131',\n",
       " '*-132',\n",
       " '*-133',\n",
       " '*-134',\n",
       " '*-135',\n",
       " '*-136',\n",
       " '*-137',\n",
       " '*-138',\n",
       " '*-139',\n",
       " '*-14',\n",
       " '*-140',\n",
       " '*-141',\n",
       " '*-142',\n",
       " '*-144',\n",
       " '*-145',\n",
       " '*-146',\n",
       " '*-147',\n",
       " '*-149',\n",
       " '*-15',\n",
       " '*-150',\n",
       " '*-151',\n",
       " '*-152',\n",
       " '*-153',\n",
       " '*-154',\n",
       " '*-155',\n",
       " '*-156',\n",
       " '*-157',\n",
       " '*-158',\n",
       " '*-159',\n",
       " '*-16',\n",
       " '*-160',\n",
       " '*-161',\n",
       " '*-162',\n",
       " '*-163',\n",
       " '*-164',\n",
       " '*-165',\n",
       " '*-166',\n",
       " '*-17',\n",
       " '*-18',\n",
       " '*-19',\n",
       " '*-2',\n",
       " '*-20',\n",
       " '*-21',\n",
       " '*-22',\n",
       " '*-23',\n",
       " '*-24',\n",
       " '*-25',\n",
       " '*-26',\n",
       " '*-27',\n",
       " '*-28',\n",
       " '*-29',\n",
       " '*-3',\n",
       " '*-30',\n",
       " '*-31',\n",
       " '*-32',\n",
       " '*-33',\n",
       " '*-34',\n",
       " '*-35',\n",
       " '*-36',\n",
       " '*-37',\n",
       " '*-38',\n",
       " '*-39',\n",
       " '*-4',\n",
       " '*-40',\n",
       " '*-41',\n",
       " '*-42',\n",
       " '*-43',\n",
       " '*-44',\n",
       " '*-45',\n",
       " '*-46',\n",
       " '*-47',\n",
       " '*-48',\n",
       " '*-49',\n",
       " '*-5',\n",
       " '*-50',\n",
       " '*-51',\n",
       " '*-52',\n",
       " '*-53',\n",
       " '*-54',\n",
       " '*-55',\n",
       " '*-56',\n",
       " '*-57',\n",
       " '*-58',\n",
       " '*-59',\n",
       " '*-6',\n",
       " '*-60',\n",
       " '*-61',\n",
       " '*-62',\n",
       " '*-63',\n",
       " '*-64',\n",
       " '*-66',\n",
       " '*-67',\n",
       " '*-68',\n",
       " '*-69',\n",
       " '*-7',\n",
       " '*-70',\n",
       " '*-71',\n",
       " '*-72',\n",
       " '*-73',\n",
       " '*-74',\n",
       " '*-75',\n",
       " '*-76',\n",
       " '*-77',\n",
       " '*-78',\n",
       " '*-79',\n",
       " '*-8',\n",
       " '*-80',\n",
       " '*-81',\n",
       " '*-82',\n",
       " '*-83',\n",
       " '*-84',\n",
       " '*-85',\n",
       " '*-86',\n",
       " '*-87',\n",
       " '*-88',\n",
       " '*-89',\n",
       " '*-9',\n",
       " '*-90',\n",
       " '*-91',\n",
       " '*-92',\n",
       " '*-93',\n",
       " '*-94',\n",
       " '*-95',\n",
       " '*-96',\n",
       " '*-97',\n",
       " '*-98',\n",
       " '*-99',\n",
       " '*?*',\n",
       " '*EXP*-1',\n",
       " '*EXP*-2',\n",
       " '*EXP*-3',\n",
       " '*ICH*-1',\n",
       " '*ICH*-2',\n",
       " '*ICH*-3',\n",
       " '*ICH*-4',\n",
       " '*NOT*',\n",
       " '*PPA*-1',\n",
       " '*PPA*-2',\n",
       " '*PPA*-3',\n",
       " '*RNR*-1',\n",
       " '*RNR*-2',\n",
       " '*RNR*-4',\n",
       " '*T*-1',\n",
       " '*T*-10',\n",
       " '*T*-100',\n",
       " '*T*-101',\n",
       " '*T*-102',\n",
       " '*T*-103',\n",
       " '*T*-104',\n",
       " '*T*-105',\n",
       " '*T*-106',\n",
       " '*T*-107',\n",
       " '*T*-108',\n",
       " '*T*-109',\n",
       " '*T*-11',\n",
       " '*T*-110',\n",
       " '*T*-111',\n",
       " '*T*-112',\n",
       " '*T*-113',\n",
       " '*T*-114',\n",
       " '*T*-115',\n",
       " '*T*-116',\n",
       " '*T*-117',\n",
       " '*T*-118',\n",
       " '*T*-119',\n",
       " '*T*-12',\n",
       " '*T*-120',\n",
       " '*T*-121',\n",
       " '*T*-122',\n",
       " '*T*-123',\n",
       " '*T*-124',\n",
       " '*T*-125',\n",
       " '*T*-126',\n",
       " '*T*-127',\n",
       " '*T*-128',\n",
       " '*T*-129',\n",
       " '*T*-13',\n",
       " '*T*-130',\n",
       " '*T*-131',\n",
       " '*T*-132',\n",
       " '*T*-133',\n",
       " '*T*-134',\n",
       " '*T*-135',\n",
       " '*T*-136',\n",
       " '*T*-137',\n",
       " '*T*-138',\n",
       " '*T*-139',\n",
       " '*T*-14',\n",
       " '*T*-140',\n",
       " '*T*-141',\n",
       " '*T*-142',\n",
       " '*T*-143',\n",
       " '*T*-144',\n",
       " '*T*-145',\n",
       " '*T*-146',\n",
       " '*T*-147',\n",
       " '*T*-148',\n",
       " '*T*-149',\n",
       " '*T*-15',\n",
       " '*T*-150',\n",
       " '*T*-151',\n",
       " '*T*-152',\n",
       " '*T*-153',\n",
       " '*T*-154',\n",
       " '*T*-155',\n",
       " '*T*-156',\n",
       " '*T*-157',\n",
       " '*T*-158',\n",
       " '*T*-159',\n",
       " '*T*-16',\n",
       " '*T*-160',\n",
       " '*T*-161',\n",
       " '*T*-162',\n",
       " '*T*-163',\n",
       " '*T*-164',\n",
       " '*T*-165',\n",
       " '*T*-166',\n",
       " '*T*-167',\n",
       " '*T*-168',\n",
       " '*T*-169',\n",
       " '*T*-17',\n",
       " '*T*-170',\n",
       " '*T*-171',\n",
       " '*T*-172',\n",
       " '*T*-173',\n",
       " '*T*-174',\n",
       " '*T*-175',\n",
       " '*T*-176',\n",
       " '*T*-177',\n",
       " '*T*-178',\n",
       " '*T*-179',\n",
       " '*T*-18',\n",
       " '*T*-180',\n",
       " '*T*-181',\n",
       " '*T*-182',\n",
       " '*T*-183',\n",
       " '*T*-184',\n",
       " '*T*-185',\n",
       " '*T*-186',\n",
       " '*T*-187',\n",
       " '*T*-188',\n",
       " '*T*-189',\n",
       " '*T*-19',\n",
       " '*T*-190',\n",
       " '*T*-191',\n",
       " '*T*-192',\n",
       " '*T*-193',\n",
       " '*T*-194',\n",
       " '*T*-195',\n",
       " '*T*-196',\n",
       " '*T*-197',\n",
       " '*T*-198',\n",
       " '*T*-199',\n",
       " '*T*-2',\n",
       " '*T*-20',\n",
       " '*T*-200',\n",
       " '*T*-201',\n",
       " '*T*-202',\n",
       " '*T*-203',\n",
       " '*T*-204',\n",
       " '*T*-205',\n",
       " '*T*-206',\n",
       " '*T*-207',\n",
       " '*T*-208',\n",
       " '*T*-21',\n",
       " '*T*-210',\n",
       " '*T*-211',\n",
       " '*T*-212',\n",
       " '*T*-213',\n",
       " '*T*-214',\n",
       " '*T*-215',\n",
       " '*T*-216',\n",
       " '*T*-217',\n",
       " '*T*-218',\n",
       " '*T*-219',\n",
       " '*T*-22',\n",
       " '*T*-220',\n",
       " '*T*-221',\n",
       " '*T*-222',\n",
       " '*T*-223',\n",
       " '*T*-224',\n",
       " '*T*-225',\n",
       " '*T*-226',\n",
       " '*T*-227',\n",
       " '*T*-228',\n",
       " '*T*-229',\n",
       " '*T*-23',\n",
       " '*T*-230',\n",
       " '*T*-231',\n",
       " '*T*-232',\n",
       " '*T*-233',\n",
       " '*T*-234',\n",
       " '*T*-235',\n",
       " '*T*-236',\n",
       " '*T*-237',\n",
       " '*T*-238',\n",
       " '*T*-239',\n",
       " '*T*-24',\n",
       " '*T*-240',\n",
       " '*T*-241',\n",
       " '*T*-242',\n",
       " '*T*-243',\n",
       " '*T*-244',\n",
       " '*T*-245',\n",
       " '*T*-246',\n",
       " '*T*-247',\n",
       " '*T*-248',\n",
       " '*T*-249',\n",
       " '*T*-25',\n",
       " '*T*-250',\n",
       " '*T*-251',\n",
       " '*T*-252',\n",
       " '*T*-253',\n",
       " '*T*-254',\n",
       " '*T*-255',\n",
       " '*T*-256',\n",
       " '*T*-257',\n",
       " '*T*-258',\n",
       " '*T*-259',\n",
       " '*T*-26',\n",
       " '*T*-260',\n",
       " '*T*-27',\n",
       " '*T*-28',\n",
       " '*T*-29',\n",
       " '*T*-3',\n",
       " '*T*-30',\n",
       " '*T*-31',\n",
       " '*T*-32',\n",
       " '*T*-33',\n",
       " '*T*-34',\n",
       " '*T*-35',\n",
       " '*T*-36',\n",
       " '*T*-37',\n",
       " '*T*-38',\n",
       " '*T*-39',\n",
       " '*T*-4',\n",
       " '*T*-40',\n",
       " '*T*-41',\n",
       " '*T*-42',\n",
       " '*T*-43',\n",
       " '*T*-44',\n",
       " '*T*-45',\n",
       " '*T*-46',\n",
       " '*T*-47',\n",
       " '*T*-48',\n",
       " '*T*-49',\n",
       " '*T*-5',\n",
       " '*T*-50',\n",
       " '*T*-51',\n",
       " '*T*-52',\n",
       " '*T*-53',\n",
       " '*T*-54',\n",
       " '*T*-55',\n",
       " '*T*-56',\n",
       " '*T*-57',\n",
       " '*T*-58',\n",
       " '*T*-59',\n",
       " '*T*-6',\n",
       " '*T*-60',\n",
       " '*T*-61',\n",
       " '*T*-62',\n",
       " '*T*-63',\n",
       " '*T*-64',\n",
       " '*T*-65',\n",
       " '*T*-66',\n",
       " '*T*-67',\n",
       " '*T*-68',\n",
       " '*T*-69',\n",
       " '*T*-7',\n",
       " '*T*-70',\n",
       " '*T*-71',\n",
       " '*T*-72',\n",
       " '*T*-73',\n",
       " '*T*-74',\n",
       " '*T*-75',\n",
       " '*T*-76',\n",
       " '*T*-77',\n",
       " '*T*-78',\n",
       " '*T*-79',\n",
       " '*T*-8',\n",
       " '*T*-80',\n",
       " '*T*-81',\n",
       " '*T*-82',\n",
       " '*T*-83',\n",
       " '*T*-84',\n",
       " '*T*-85',\n",
       " '*T*-86',\n",
       " '*T*-87',\n",
       " '*T*-88',\n",
       " '*T*-89',\n",
       " '*T*-9',\n",
       " '*T*-90',\n",
       " '*T*-91',\n",
       " '*T*-92',\n",
       " '*T*-93',\n",
       " '*T*-94',\n",
       " '*T*-95',\n",
       " '*T*-96',\n",
       " '*T*-97',\n",
       " '*T*-98',\n",
       " '*T*-99',\n",
       " '*U*',\n",
       " ',',\n",
       " '-',\n",
       " '--',\n",
       " '-LCB-',\n",
       " '-LRB-',\n",
       " '-RCB-',\n",
       " '-RRB-',\n",
       " '.',\n",
       " '...',\n",
       " '0',\n",
       " '0.0085',\n",
       " '0.05',\n",
       " '0.1',\n",
       " '0.16',\n",
       " '0.2',\n",
       " '0.25',\n",
       " '0.28',\n",
       " '0.3',\n",
       " '0.4',\n",
       " '0.5',\n",
       " '0.50',\n",
       " '0.54',\n",
       " '0.56',\n",
       " '0.60',\n",
       " '0.7',\n",
       " '0.82',\n",
       " '0.84',\n",
       " '0.9',\n",
       " '0.95',\n",
       " '0.99',\n",
       " '1',\n",
       " '1,000',\n",
       " '1,050,000',\n",
       " '1,100',\n",
       " '1,200',\n",
       " '1,298',\n",
       " '1,400',\n",
       " '1,460',\n",
       " '1,500',\n",
       " '1,570',\n",
       " '1,620',\n",
       " '1,880',\n",
       " '1.01',\n",
       " '1.1',\n",
       " '1.125',\n",
       " '1.14',\n",
       " '1.1650',\n",
       " '1.17',\n",
       " '1.18',\n",
       " '1.19',\n",
       " '1.2',\n",
       " '1.20',\n",
       " '1.24',\n",
       " '1.25',\n",
       " '1.26',\n",
       " '1.28',\n",
       " '1.35',\n",
       " '1.39',\n",
       " '1.4',\n",
       " '1.457',\n",
       " '1.46',\n",
       " '1.49',\n",
       " '1.5',\n",
       " '1.50',\n",
       " '1.55',\n",
       " '1.56',\n",
       " '1.5755',\n",
       " '1.5805',\n",
       " '1.6',\n",
       " '1.61',\n",
       " '1.637',\n",
       " '1.64',\n",
       " '1.65',\n",
       " '1.7',\n",
       " '1.75',\n",
       " '1.76',\n",
       " '1.8',\n",
       " '1.82',\n",
       " '1.8415',\n",
       " '1.85',\n",
       " '1.8500',\n",
       " '1.9',\n",
       " '1.916',\n",
       " '1.92',\n",
       " '10',\n",
       " '10,000',\n",
       " '10-day',\n",
       " '10-lap',\n",
       " '10-year',\n",
       " '10.19',\n",
       " '10.2',\n",
       " '10.5',\n",
       " '100',\n",
       " '100,000',\n",
       " '100,980',\n",
       " '100-megabyte',\n",
       " '100-share',\n",
       " '101',\n",
       " '102',\n",
       " '103',\n",
       " '105',\n",
       " '106',\n",
       " '107',\n",
       " '107.03',\n",
       " '107.9',\n",
       " '108',\n",
       " '109.73',\n",
       " '10th',\n",
       " '11',\n",
       " '11,000',\n",
       " '11,390,000',\n",
       " '11,762',\n",
       " '11-month-old',\n",
       " '11.10',\n",
       " '11.5',\n",
       " '11.57',\n",
       " '11.6',\n",
       " '11.72',\n",
       " '11.95',\n",
       " '110',\n",
       " '111',\n",
       " '112.9',\n",
       " '113.2',\n",
       " '114',\n",
       " '115',\n",
       " '116.3',\n",
       " '116.4',\n",
       " '116.7',\n",
       " '116.9',\n",
       " '118',\n",
       " '118.6',\n",
       " '119',\n",
       " '11\\\\/16',\n",
       " '11th',\n",
       " '12',\n",
       " '12,252',\n",
       " '12-member',\n",
       " '12-point',\n",
       " '12-year',\n",
       " '12.09',\n",
       " '12.5',\n",
       " '12.52',\n",
       " '12.68',\n",
       " '12.7',\n",
       " '12.82',\n",
       " '12.97',\n",
       " '120',\n",
       " '120,000',\n",
       " '120-a-share',\n",
       " '120.7',\n",
       " '1206.26',\n",
       " '121.6',\n",
       " '125',\n",
       " '126,000',\n",
       " '126.1',\n",
       " '126.15',\n",
       " '127.03',\n",
       " '128',\n",
       " '129.91',\n",
       " '12\\\\/32',\n",
       " '13',\n",
       " '13,056',\n",
       " '13.1',\n",
       " '13.15',\n",
       " '13.5',\n",
       " '13.50',\n",
       " '13.625',\n",
       " '13.65',\n",
       " '13.73',\n",
       " '13.8',\n",
       " '13.90',\n",
       " '130',\n",
       " '130.6',\n",
       " '130.7',\n",
       " '131.01',\n",
       " '132',\n",
       " '132,000',\n",
       " '132.9',\n",
       " '133',\n",
       " '133.7',\n",
       " '133.8',\n",
       " '135',\n",
       " '138',\n",
       " '139',\n",
       " '13\\\\/16',\n",
       " '14',\n",
       " '14,821',\n",
       " '14-hour',\n",
       " '14.',\n",
       " '14.00',\n",
       " '14.13',\n",
       " '14.26',\n",
       " '14.28',\n",
       " '14.43',\n",
       " '14.5',\n",
       " '14.53',\n",
       " '14.54',\n",
       " '14.6',\n",
       " '14.75',\n",
       " '14.99',\n",
       " '140',\n",
       " '141.9',\n",
       " '142.84',\n",
       " '142.85',\n",
       " '143.08',\n",
       " '143.80',\n",
       " '143.93',\n",
       " '144',\n",
       " '145',\n",
       " '148',\n",
       " '148.9',\n",
       " '149',\n",
       " '149.9',\n",
       " '14\\\\/32',\n",
       " '15',\n",
       " '15,000',\n",
       " '15-day',\n",
       " '15.5',\n",
       " '150',\n",
       " '150,000',\n",
       " '150-point',\n",
       " '150.00',\n",
       " '152,000',\n",
       " '153.3',\n",
       " '154,240,000',\n",
       " '154.2',\n",
       " '155',\n",
       " '158,666',\n",
       " '16',\n",
       " '16,000',\n",
       " '16,072',\n",
       " '16.05',\n",
       " '16.09',\n",
       " '16.125',\n",
       " '16.2',\n",
       " '16.5',\n",
       " '16.68',\n",
       " '16.7',\n",
       " '16.9',\n",
       " '160',\n",
       " '1614',\n",
       " '1637',\n",
       " '169.9',\n",
       " '16\\\\/32',\n",
       " '17',\n",
       " '17-year-old',\n",
       " '17.3',\n",
       " '17.4',\n",
       " '17.5',\n",
       " '17.95',\n",
       " '170',\n",
       " '170,000',\n",
       " '170,262',\n",
       " '1738.1',\n",
       " '175',\n",
       " '176',\n",
       " '176.1',\n",
       " '177',\n",
       " '1787',\n",
       " '179',\n",
       " '18',\n",
       " '18,000',\n",
       " '18,444',\n",
       " '18-a-share',\n",
       " '18-year-old',\n",
       " '18.3',\n",
       " '18.6',\n",
       " '18.95',\n",
       " '180',\n",
       " '184',\n",
       " '185.9',\n",
       " '187',\n",
       " '188',\n",
       " '188.84',\n",
       " '19',\n",
       " '19-month-old',\n",
       " '19.3',\n",
       " '19.50',\n",
       " '19.6',\n",
       " '19.94',\n",
       " '19.95',\n",
       " '190',\n",
       " '190-point',\n",
       " '1901',\n",
       " '1903',\n",
       " '191.9',\n",
       " '1917',\n",
       " '1920s',\n",
       " '1925',\n",
       " '1928-33',\n",
       " '1929',\n",
       " '1933',\n",
       " '1934',\n",
       " '1937-40',\n",
       " '1940s',\n",
       " '1948',\n",
       " '195',\n",
       " '1950s',\n",
       " '1953',\n",
       " '1955',\n",
       " '1956',\n",
       " '1960s',\n",
       " '1961',\n",
       " '1965',\n",
       " '1966',\n",
       " '1967',\n",
       " '1968',\n",
       " '1969',\n",
       " '1970',\n",
       " '1970s',\n",
       " '1971',\n",
       " '1972',\n",
       " '1973',\n",
       " '1973-75',\n",
       " '1975',\n",
       " '1976',\n",
       " '1977',\n",
       " '1979',\n",
       " '198',\n",
       " '1980',\n",
       " '1980s',\n",
       " '1981',\n",
       " '1982',\n",
       " '1983',\n",
       " '1983-85',\n",
       " '1984',\n",
       " '1985',\n",
       " '1986',\n",
       " '1986-87',\n",
       " '1987',\n",
       " '1987-88',\n",
       " '1988',\n",
       " '1988-89',\n",
       " '1989',\n",
       " '1989-90',\n",
       " '1990',\n",
       " '1990-91',\n",
       " '1990s',\n",
       " '1991',\n",
       " '1991-1999',\n",
       " '1991-2000',\n",
       " '1992',\n",
       " '1992-1999',\n",
       " '1993',\n",
       " '1994',\n",
       " '1995',\n",
       " '1996',\n",
       " '1997',\n",
       " '1998',\n",
       " '1999',\n",
       " '1:30',\n",
       " '1\\\\/10th',\n",
       " '1\\\\/2',\n",
       " '1\\\\/4',\n",
       " '1\\\\/8',\n",
       " '1st',\n",
       " '2',\n",
       " '2,000',\n",
       " '2,050-passenger',\n",
       " '2,099',\n",
       " '2,303,328',\n",
       " '2,410',\n",
       " '2,500',\n",
       " '2,700',\n",
       " '2-3',\n",
       " '2-8',\n",
       " '2.07',\n",
       " '2.1',\n",
       " '2.15',\n",
       " '2.19',\n",
       " '2.2',\n",
       " '2.25',\n",
       " '2.29',\n",
       " '2.3',\n",
       " '2.30',\n",
       " '2.35',\n",
       " '2.375',\n",
       " '2.4',\n",
       " '2.42',\n",
       " '2.44',\n",
       " '2.46',\n",
       " '2.47',\n",
       " '2.5',\n",
       " '2.50',\n",
       " '2.6',\n",
       " '2.62',\n",
       " '2.65',\n",
       " '2.7',\n",
       " '2.75',\n",
       " '2.8',\n",
       " '2.80',\n",
       " '2.87',\n",
       " '2.875',\n",
       " '2.9',\n",
       " '2.95',\n",
       " '20',\n",
       " '20,000',\n",
       " '20-point',\n",
       " '20-stock',\n",
       " '20.07',\n",
       " '20.5',\n",
       " '200',\n",
       " '200,000',\n",
       " '2000',\n",
       " '2003\\\\/2007',\n",
       " '2005',\n",
       " '2009',\n",
       " '2017',\n",
       " '2019',\n",
       " '2029',\n",
       " '203',\n",
       " '20s',\n",
       " '21',\n",
       " '21,000',\n",
       " '21-month',\n",
       " '21.1',\n",
       " '21.9',\n",
       " '210',\n",
       " '210,000',\n",
       " '212',\n",
       " '214',\n",
       " '2141.7',\n",
       " '2160.1',\n",
       " '2163.2',\n",
       " '22',\n",
       " '22.75',\n",
       " '220',\n",
       " '220.45',\n",
       " '221.4',\n",
       " '225',\n",
       " '225,000',\n",
       " '225.6',\n",
       " '226,570,380',\n",
       " '227',\n",
       " '228',\n",
       " '22\\\\/32',\n",
       " '23',\n",
       " '23,000',\n",
       " '23,403',\n",
       " '23.25',\n",
       " '23.4',\n",
       " '23.5',\n",
       " '23.72',\n",
       " '230-215',\n",
       " '234.4',\n",
       " '235',\n",
       " '236.74',\n",
       " '236.79',\n",
       " '237-seat',\n",
       " '238,000-circulation',\n",
       " '24',\n",
       " '24,000',\n",
       " '24.95',\n",
       " '240',\n",
       " '240,000',\n",
       " '240-page',\n",
       " '241',\n",
       " '244,000',\n",
       " '245',\n",
       " '25',\n",
       " '25,000',\n",
       " '25-year-old',\n",
       " '25.50',\n",
       " '25.6',\n",
       " '250',\n",
       " '250,000',\n",
       " '251.2',\n",
       " '257',\n",
       " '26',\n",
       " '26,000',\n",
       " '26,956',\n",
       " '26.2',\n",
       " '26.5',\n",
       " '26.8',\n",
       " '260',\n",
       " '263.07',\n",
       " '2645.90',\n",
       " '266',\n",
       " '2691.19',\n",
       " '27',\n",
       " '27-year',\n",
       " '27.1',\n",
       " '27.4',\n",
       " '270',\n",
       " '271,124',\n",
       " '271-147',\n",
       " '273.5',\n",
       " '274',\n",
       " '275',\n",
       " '278.7',\n",
       " '28',\n",
       " '28.25',\n",
       " '28.36',\n",
       " '28.4',\n",
       " '28.5',\n",
       " '28.53',\n",
       " '28.6',\n",
       " '280',\n",
       " '282',\n",
       " '286',\n",
       " '29',\n",
       " '29.3',\n",
       " '29.4',\n",
       " '29.9',\n",
       " '292.32',\n",
       " '295',\n",
       " '29year',\n",
       " '2\\\\/32',\n",
       " '3',\n",
       " '3,040,000',\n",
       " '3,250,000',\n",
       " '3,288,453',\n",
       " '3,500',\n",
       " '3,600',\n",
       " '3-4',\n",
       " '3.01',\n",
       " '3.04',\n",
       " '3.1',\n",
       " '3.16',\n",
       " '3.18',\n",
       " '3.19',\n",
       " '3.2',\n",
       " '3.20',\n",
       " '3.23',\n",
       " '3.253',\n",
       " '3.28',\n",
       " '3.3',\n",
       " '3.35',\n",
       " '3.375',\n",
       " '3.4',\n",
       " '3.42',\n",
       " '3.43',\n",
       " '3.5',\n",
       " '3.55',\n",
       " '3.6',\n",
       " '3.61',\n",
       " '3.625',\n",
       " '3.7',\n",
       " '3.75',\n",
       " '3.8',\n",
       " '3.80',\n",
       " ...]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(set(text7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The',\n",
       " 'family',\n",
       " 'of',\n",
       " 'Dashwood',\n",
       " 'had',\n",
       " 'long',\n",
       " 'been',\n",
       " 'settled',\n",
       " 'in',\n",
       " 'Sussex',\n",
       " '.']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'awaken'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text4[173]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "173"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text4.index('awaken')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['to',\n",
       " 'establish',\n",
       " 'a',\n",
       " 'system',\n",
       " 'of',\n",
       " 'buccaneering',\n",
       " 'in',\n",
       " 'the',\n",
       " 'neighboring',\n",
       " 'seas',\n",
       " ',',\n",
       " 'to',\n",
       " 'the',\n",
       " 'great',\n",
       " 'annoyance',\n",
       " 'of',\n",
       " 'the',\n",
       " 'commerce',\n",
       " 'of',\n",
       " 'the']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text4[16715:16735]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdist1 = FreqDist(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<FreqDist with 19317 samples and 260819 outcomes>\n"
     ]
    }
   ],
   "source": [
    "print(fdist1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(',', 18713),\n",
       " ('the', 13721),\n",
       " ('.', 6862),\n",
       " ('of', 6536),\n",
       " ('and', 6024),\n",
       " ('a', 4569),\n",
       " ('to', 4542),\n",
       " (';', 4072),\n",
       " ('in', 3916),\n",
       " ('that', 2982),\n",
       " (\"'\", 2684),\n",
       " ('-', 2552),\n",
       " ('his', 2459),\n",
       " ('it', 2209),\n",
       " ('I', 2124),\n",
       " ('s', 1739),\n",
       " ('is', 1695),\n",
       " ('he', 1661),\n",
       " ('with', 1659),\n",
       " ('was', 1632),\n",
       " ('as', 1620),\n",
       " ('\"', 1478),\n",
       " ('all', 1462),\n",
       " ('for', 1414),\n",
       " ('this', 1280),\n",
       " ('!', 1269),\n",
       " ('at', 1231),\n",
       " ('by', 1137),\n",
       " ('but', 1113),\n",
       " ('not', 1103),\n",
       " ('--', 1070),\n",
       " ('him', 1058),\n",
       " ('from', 1052),\n",
       " ('be', 1030),\n",
       " ('on', 1005),\n",
       " ('so', 918),\n",
       " ('whale', 906),\n",
       " ('one', 889),\n",
       " ('you', 841),\n",
       " ('had', 767),\n",
       " ('have', 760),\n",
       " ('there', 715),\n",
       " ('But', 705),\n",
       " ('or', 697),\n",
       " ('were', 680),\n",
       " ('now', 646),\n",
       " ('which', 640),\n",
       " ('?', 637),\n",
       " ('me', 627),\n",
       " ('like', 624)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist1.most_common(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_list = [ len(w) for w in text1 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdist2 = FreqDist(len_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3, 50223),\n",
       " (1, 47933),\n",
       " (4, 42345),\n",
       " (2, 38513),\n",
       " (5, 26597),\n",
       " (6, 17111),\n",
       " (7, 14399),\n",
       " (8, 9966),\n",
       " (9, 6428),\n",
       " (10, 3528),\n",
       " (11, 1873),\n",
       " (12, 1053),\n",
       " (13, 567),\n",
       " (14, 177),\n",
       " (15, 70),\n",
       " (16, 22),\n",
       " (17, 12),\n",
       " (18, 1),\n",
       " (20, 1)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist2.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist2.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50223"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist2[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "V = set(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_words = [ w for w in V if len(w) > 15 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CIRCUMNAVIGATION',\n",
       " 'Physiognomically',\n",
       " 'apprehensiveness',\n",
       " 'cannibalistically',\n",
       " 'characteristically',\n",
       " 'circumnavigating',\n",
       " 'circumnavigation',\n",
       " 'circumnavigations',\n",
       " 'comprehensiveness',\n",
       " 'hermaphroditical',\n",
       " 'indiscriminately',\n",
       " 'indispensableness',\n",
       " 'irresistibleness',\n",
       " 'physiognomically',\n",
       " 'preternaturalness',\n",
       " 'responsibilities',\n",
       " 'simultaneousness',\n",
       " 'subterraneousness',\n",
       " 'supernaturalness',\n",
       " 'superstitiousness',\n",
       " 'uncomfortableness',\n",
       " 'uncompromisedness',\n",
       " 'undiscriminating',\n",
       " 'uninterpenetratingly']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(long_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdist5 = FreqDist(text5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_7_7 = [ w for w in set(text5) if len(w) > 7 and fdist5[w] > 7 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['football',\n",
       " '#14-19teens',\n",
       " 'innocent',\n",
       " '((((((((((',\n",
       " 'anything',\n",
       " 'listening',\n",
       " 'something',\n",
       " 'seriously',\n",
       " '#talkcity_adults',\n",
       " 'everyone',\n",
       " 'remember',\n",
       " 'tomorrow',\n",
       " '........',\n",
       " 'computer',\n",
       " 'watching',\n",
       " 'actually',\n",
       " 'Question',\n",
       " 'cute.-ass',\n",
       " 'together']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_7_7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['comfortableness',\n",
       " 'honourableness',\n",
       " 'immutableness',\n",
       " 'indispensableness',\n",
       " 'indomitableness',\n",
       " 'intolerableness',\n",
       " 'palpableness',\n",
       " 'reasonableness',\n",
       " 'uncomfortableness']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted( w for w in set(text1) if w.endswith('ableness') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A',\n",
       " 'Aaaaaaaaah',\n",
       " 'Aaaaaaaah',\n",
       " 'Aaaaaah',\n",
       " 'Aaaah',\n",
       " 'Aaaaugh',\n",
       " 'Aaagh',\n",
       " 'Aaah',\n",
       " 'Aaauggh',\n",
       " 'Aaaugh',\n",
       " 'Aaauugh',\n",
       " 'Aagh',\n",
       " 'Aah',\n",
       " 'Aauuggghhh',\n",
       " 'Aauuugh',\n",
       " 'Aauuuuugh',\n",
       " 'Aauuuves',\n",
       " 'Action',\n",
       " 'Actually',\n",
       " 'African',\n",
       " 'Ages',\n",
       " 'Aggh',\n",
       " 'Agh',\n",
       " 'Ah',\n",
       " 'Ahh',\n",
       " 'Alice',\n",
       " 'All',\n",
       " 'Allo',\n",
       " 'Almighty',\n",
       " 'Alright',\n",
       " 'Am',\n",
       " 'Amen',\n",
       " 'An',\n",
       " 'Anarcho',\n",
       " 'And',\n",
       " 'Angnor',\n",
       " 'Anthrax',\n",
       " 'Antioch',\n",
       " 'Anybody',\n",
       " 'Anyway',\n",
       " 'Apples',\n",
       " 'Aramaic',\n",
       " 'Are',\n",
       " 'Arimathea',\n",
       " 'Armaments',\n",
       " 'Arthur',\n",
       " 'As',\n",
       " 'Ask',\n",
       " 'Assyria',\n",
       " 'At',\n",
       " 'Attila',\n",
       " 'Augh',\n",
       " 'Autumn',\n",
       " 'Auuuuuuuugh',\n",
       " 'Away',\n",
       " 'Ay',\n",
       " 'Ayy',\n",
       " 'B',\n",
       " 'Back',\n",
       " 'Bad',\n",
       " 'Badon',\n",
       " 'Battle',\n",
       " 'Be',\n",
       " 'Beast',\n",
       " 'Bedevere',\n",
       " 'Bedwere',\n",
       " 'Behold',\n",
       " 'Between',\n",
       " 'Beyond',\n",
       " 'Black',\n",
       " 'Bloody',\n",
       " 'Blue',\n",
       " 'Bon',\n",
       " 'Bones',\n",
       " 'Book',\n",
       " 'Bors',\n",
       " 'Brave',\n",
       " 'Bravely',\n",
       " 'Bravest',\n",
       " 'Bread',\n",
       " 'Bridge',\n",
       " 'Bring',\n",
       " 'Bristol',\n",
       " 'Britain',\n",
       " 'Britons',\n",
       " 'Brother',\n",
       " 'Build',\n",
       " 'Burn',\n",
       " 'But',\n",
       " 'By',\n",
       " 'C',\n",
       " 'Caerbannog',\n",
       " 'Camaaaaaargue',\n",
       " 'Camelot',\n",
       " 'Castle',\n",
       " 'Chapter',\n",
       " 'Charge',\n",
       " 'Chaste',\n",
       " 'Cherries',\n",
       " 'Chicken',\n",
       " 'Chickennn',\n",
       " 'Chop',\n",
       " 'Christ',\n",
       " 'Churches',\n",
       " 'Cider',\n",
       " 'Clark',\n",
       " 'Clear',\n",
       " 'Come',\n",
       " 'Concorde',\n",
       " 'Consult',\n",
       " 'Cornwall',\n",
       " 'Could',\n",
       " 'Course',\n",
       " 'Court',\n",
       " 'Crapper',\n",
       " 'Cut',\n",
       " 'Dappy',\n",
       " 'Death',\n",
       " 'Defeat',\n",
       " 'Dennis',\n",
       " 'Did',\n",
       " 'Didn',\n",
       " 'Dingo',\n",
       " 'Dis',\n",
       " 'Divine',\n",
       " 'Do',\n",
       " 'Doctor',\n",
       " 'Does',\n",
       " 'Don',\n",
       " 'Dragon',\n",
       " 'Dramatically',\n",
       " 'Ecky',\n",
       " 'Ector',\n",
       " 'Eee',\n",
       " 'Eh',\n",
       " 'Enchanter',\n",
       " 'England',\n",
       " 'English',\n",
       " 'Erbert',\n",
       " 'Ere',\n",
       " 'Erm',\n",
       " 'Eternal',\n",
       " 'European',\n",
       " 'Even',\n",
       " 'Every',\n",
       " 'Everything',\n",
       " 'Ewing',\n",
       " 'Exactly',\n",
       " 'Excalibur',\n",
       " 'Excuse',\n",
       " 'Explain',\n",
       " 'Far',\n",
       " 'Farewell',\n",
       " 'Father',\n",
       " 'Fetchez',\n",
       " 'Fiends',\n",
       " 'Fine',\n",
       " 'First',\n",
       " 'Firstly',\n",
       " 'Five',\n",
       " 'Follow',\n",
       " 'For',\n",
       " 'Forgive',\n",
       " 'Forward',\n",
       " 'Found',\n",
       " 'Four',\n",
       " 'France',\n",
       " 'Frank',\n",
       " 'French',\n",
       " 'Gable',\n",
       " 'Galahad',\n",
       " 'Gallahad',\n",
       " 'Gawain',\n",
       " 'Get',\n",
       " 'Go',\n",
       " 'God',\n",
       " 'Good',\n",
       " 'Gorge',\n",
       " 'Grail',\n",
       " 'Great',\n",
       " 'Greetings',\n",
       " 'Grenade',\n",
       " 'Guards',\n",
       " 'Guy',\n",
       " 'Ha',\n",
       " 'Hah',\n",
       " 'Hallo',\n",
       " 'Halt',\n",
       " 'Hand',\n",
       " 'Hang',\n",
       " 'Have',\n",
       " 'Haw',\n",
       " 'He',\n",
       " 'Hee',\n",
       " 'Heee',\n",
       " 'Heh',\n",
       " 'Hello',\n",
       " 'Help',\n",
       " 'Herbert',\n",
       " 'Here',\n",
       " 'Hey',\n",
       " 'Hic',\n",
       " 'Hill',\n",
       " 'Himself',\n",
       " 'His',\n",
       " 'Hiyaah',\n",
       " 'Hiyah',\n",
       " 'Hiyya',\n",
       " 'Hm',\n",
       " 'Hmm',\n",
       " 'Ho',\n",
       " 'Hoa',\n",
       " 'Hold',\n",
       " 'Holy',\n",
       " 'Honestly',\n",
       " 'Hoo',\n",
       " 'Hooray',\n",
       " 'How',\n",
       " 'Huh',\n",
       " 'Hurry',\n",
       " 'Huy',\n",
       " 'Huyah',\n",
       " 'Hya',\n",
       " 'Hyy',\n",
       " 'I',\n",
       " 'Idiom',\n",
       " 'Iesu',\n",
       " 'If',\n",
       " 'Iiiiives',\n",
       " 'Iiiives',\n",
       " 'In',\n",
       " 'Is',\n",
       " 'Isn',\n",
       " 'It',\n",
       " 'Ives',\n",
       " 'Jesus',\n",
       " 'Joseph',\n",
       " 'Just',\n",
       " 'Keep',\n",
       " 'King',\n",
       " 'Knight',\n",
       " 'Knights',\n",
       " 'Lady',\n",
       " 'Lake',\n",
       " 'Lancelot',\n",
       " 'Launcelot',\n",
       " 'Lead',\n",
       " 'Leaving',\n",
       " 'Let',\n",
       " 'Lie',\n",
       " 'Like',\n",
       " 'Listen',\n",
       " 'Loimbard',\n",
       " 'Look',\n",
       " 'Looks',\n",
       " 'Lord',\n",
       " 'Lucky',\n",
       " 'Make',\n",
       " 'Man',\n",
       " 'May',\n",
       " 'Maynard',\n",
       " 'Meanwhile',\n",
       " 'Mercea',\n",
       " 'Message',\n",
       " 'Midget',\n",
       " 'Mind',\n",
       " 'Mine',\n",
       " 'Mmm',\n",
       " 'Monsieur',\n",
       " 'More',\n",
       " 'Morning',\n",
       " 'Most',\n",
       " 'Mother',\n",
       " 'Mud',\n",
       " 'Must',\n",
       " 'My',\n",
       " 'N',\n",
       " 'Nador',\n",
       " 'Nay',\n",
       " 'Neee',\n",
       " 'Never',\n",
       " 'Ni',\n",
       " 'Nine',\n",
       " 'Ninepence',\n",
       " 'No',\n",
       " 'None',\n",
       " 'Not',\n",
       " 'Nothing',\n",
       " 'Now',\n",
       " 'Nu',\n",
       " 'O',\n",
       " 'Of',\n",
       " 'Off',\n",
       " 'Oh',\n",
       " 'Ohh',\n",
       " 'Old',\n",
       " 'Olfin',\n",
       " 'On',\n",
       " 'Once',\n",
       " 'One',\n",
       " 'Ooh',\n",
       " 'Oooh',\n",
       " 'Oooo',\n",
       " 'Oooohoohohooo',\n",
       " 'Oooooooh',\n",
       " 'Open',\n",
       " 'Or',\n",
       " 'Order',\n",
       " 'Other',\n",
       " 'Oui',\n",
       " 'Our',\n",
       " 'Over',\n",
       " 'Ow',\n",
       " 'Packing',\n",
       " 'Patsy',\n",
       " 'Pendragon',\n",
       " 'Peng',\n",
       " 'Perhaps',\n",
       " 'Peril',\n",
       " 'Picture',\n",
       " 'Pie',\n",
       " 'Piglet',\n",
       " 'Pin',\n",
       " 'Please',\n",
       " 'Practice',\n",
       " 'Prepare',\n",
       " 'Prince',\n",
       " 'Princess',\n",
       " 'Providence',\n",
       " 'Psalms',\n",
       " 'Pull',\n",
       " 'Pure',\n",
       " 'Put',\n",
       " 'Quick',\n",
       " 'Quickly',\n",
       " 'Quiet',\n",
       " 'Quite',\n",
       " 'Quoi',\n",
       " 'Rather',\n",
       " 'Really',\n",
       " 'Recently',\n",
       " 'Remove',\n",
       " 'Rheged',\n",
       " 'Ridden',\n",
       " 'Right',\n",
       " 'Riiight',\n",
       " 'Robin',\n",
       " 'Robinson',\n",
       " 'Roger',\n",
       " 'Round',\n",
       " 'Run',\n",
       " 'Running',\n",
       " 'S',\n",
       " 'Said',\n",
       " 'Saint',\n",
       " 'Saxons',\n",
       " 'Say',\n",
       " 'Schools',\n",
       " 'See',\n",
       " 'Seek',\n",
       " 'Shall',\n",
       " 'She',\n",
       " 'Shh',\n",
       " 'Shrubber',\n",
       " 'Shrubberies',\n",
       " 'Shut',\n",
       " 'Silence',\n",
       " 'Silly',\n",
       " 'Since',\n",
       " 'Sir',\n",
       " 'Skip',\n",
       " 'So',\n",
       " 'Sorry',\n",
       " 'Speak',\n",
       " 'Splendid',\n",
       " 'Spring',\n",
       " 'Stand',\n",
       " 'Stay',\n",
       " 'Steady',\n",
       " 'Stop',\n",
       " 'Summer',\n",
       " 'Supposing',\n",
       " 'Supreme',\n",
       " 'Surely',\n",
       " 'Swamp',\n",
       " 'Table',\n",
       " 'Tale',\n",
       " 'Tall',\n",
       " 'Tell',\n",
       " 'Thank',\n",
       " 'That',\n",
       " 'The',\n",
       " 'Thee',\n",
       " 'Then',\n",
       " 'There',\n",
       " 'Therefore',\n",
       " 'They',\n",
       " 'This',\n",
       " 'Those',\n",
       " 'Thou',\n",
       " 'Thpppppt',\n",
       " 'Thppppt',\n",
       " 'Thpppt',\n",
       " 'Thppt',\n",
       " 'Three',\n",
       " 'Throw',\n",
       " 'Thsss',\n",
       " 'Thursday',\n",
       " 'Thy',\n",
       " 'Til',\n",
       " 'Tim',\n",
       " 'Tis',\n",
       " 'To',\n",
       " 'Today',\n",
       " 'Together',\n",
       " 'Too',\n",
       " 'Torment',\n",
       " 'Tower',\n",
       " 'True',\n",
       " 'Try',\n",
       " 'Twenty',\n",
       " 'Two',\n",
       " 'U',\n",
       " 'Uh',\n",
       " 'Uhh',\n",
       " 'Ulk',\n",
       " 'Um',\n",
       " 'Umhm',\n",
       " 'Umm',\n",
       " 'Un',\n",
       " 'Unfortunately',\n",
       " 'Until',\n",
       " 'Use',\n",
       " 'Uther',\n",
       " 'Uugh',\n",
       " 'Uuh',\n",
       " 'Very',\n",
       " 'Victory',\n",
       " 'W',\n",
       " 'Waa',\n",
       " 'Wait',\n",
       " 'Walk',\n",
       " 'Wayy',\n",
       " 'We',\n",
       " 'Welcome',\n",
       " 'Well',\n",
       " 'What',\n",
       " 'When',\n",
       " 'Where',\n",
       " 'Which',\n",
       " 'Who',\n",
       " 'Whoa',\n",
       " 'Why',\n",
       " 'Will',\n",
       " 'Winston',\n",
       " 'Winter',\n",
       " 'With',\n",
       " 'Woa',\n",
       " 'Wood',\n",
       " 'Would',\n",
       " 'Y',\n",
       " 'Yapping',\n",
       " 'Yay',\n",
       " 'Yeaaah',\n",
       " 'Yeaah',\n",
       " 'Yeah',\n",
       " 'Yes',\n",
       " 'You',\n",
       " 'Your',\n",
       " 'Yup',\n",
       " 'Zoot']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted( item for item in set(text6) if item.istitle() ) #uppercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['29', '61']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted( item for item in set(sent7) if item.isdigit() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "260819"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19317"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(text1)) #num of distinct word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17231"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len( set(word.lower() for word in text1)) #process upper -> lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16948"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(word.lower() for word in text1 if word.isalpha())) #real num of dist. word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('car.n.01')]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synsets('motorcar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['car', 'auto', 'automobile', 'machine', 'motorcar']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synset('car.n.01').lemma_names() #similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a motor vehicle with four wheels; usually propelled by an internal combustion engine'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synset('car.n.01').definition()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['he needs a car to get to work']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synset('car.n.01').examples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('car.n.01'),\n",
       " Synset('car.n.02'),\n",
       " Synset('car.n.03'),\n",
       " Synset('car.n.04'),\n",
       " Synset('cable_car.n.01')]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synsets('car')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['car', 'auto', 'automobile', 'machine', 'motorcar']\n",
      "['car', 'railcar', 'railway_car', 'railroad_car']\n",
      "['car', 'gondola']\n",
      "['car', 'elevator_car']\n",
      "['cable_car', 'car']\n"
     ]
    }
   ],
   "source": [
    "for synset in wn.synsets('car'):\n",
    "    print(synset.lemma_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "motorcar = wn.synset('car.n.01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "types_of_motorcar = motorcar.hyponyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('ambulance.n.01')\n",
      "Synset('beach_wagon.n.01')\n",
      "Synset('bus.n.04')\n",
      "Synset('cab.n.03')\n",
      "Synset('compact.n.03')\n",
      "Synset('convertible.n.01')\n",
      "Synset('coupe.n.01')\n",
      "Synset('cruiser.n.01')\n",
      "Synset('electric.n.01')\n",
      "Synset('gas_guzzler.n.01')\n",
      "Synset('hardtop.n.01')\n",
      "Synset('hatchback.n.01')\n",
      "Synset('horseless_carriage.n.01')\n",
      "Synset('hot_rod.n.01')\n",
      "Synset('jeep.n.01')\n",
      "Synset('limousine.n.01')\n",
      "Synset('loaner.n.02')\n",
      "Synset('minicar.n.01')\n",
      "Synset('minivan.n.01')\n",
      "Synset('model_t.n.01')\n",
      "Synset('pace_car.n.01')\n",
      "Synset('racer.n.02')\n",
      "Synset('roadster.n.01')\n",
      "Synset('sedan.n.01')\n",
      "Synset('sport_utility.n.01')\n",
      "Synset('sports_car.n.01')\n",
      "Synset('stanley_steamer.n.01')\n",
      "Synset('stock_car.n.01')\n",
      "Synset('subcompact.n.01')\n",
      "Synset('touring_car.n.01')\n",
      "Synset('used-car.n.01')\n"
     ]
    }
   ],
   "source": [
    "for item in types_of_motorcar:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('motor_vehicle.n.01')]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "motorcar.hypernyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths = motorcar.hypernym_paths()\n",
    "len(paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['entity.n.01',\n",
       " 'physical_entity.n.01',\n",
       " 'object.n.01',\n",
       " 'whole.n.02',\n",
       " 'artifact.n.01',\n",
       " 'instrumentality.n.03',\n",
       " 'container.n.01',\n",
       " 'wheeled_vehicle.n.01',\n",
       " 'self-propelled_vehicle.n.01',\n",
       " 'motor_vehicle.n.01',\n",
       " 'car.n.01']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[synset.name() for synset in paths[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['entity.n.01',\n",
       " 'physical_entity.n.01',\n",
       " 'object.n.01',\n",
       " 'whole.n.02',\n",
       " 'artifact.n.01',\n",
       " 'instrumentality.n.03',\n",
       " 'conveyance.n.03',\n",
       " 'vehicle.n.01',\n",
       " 'wheeled_vehicle.n.01',\n",
       " 'self-propelled_vehicle.n.01',\n",
       " 'motor_vehicle.n.01',\n",
       " 'car.n.01']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[synset.name() for synset in paths[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('burl.n.02'),\n",
       " Synset('crown.n.07'),\n",
       " Synset('limb.n.02'),\n",
       " Synset('stump.n.01'),\n",
       " Synset('trunk.n.01')]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synset('tree.n.01').part_meronyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('forest.n.01')]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synset(\"tree.n.01\").member_holonyms() #tree is part of forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('step.v.01')]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synset('walk.v.01').entailments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('chew.v.01'), Synset('swallow.v.01')]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synset('eat.v.01').entailments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Lemma('demand.n.02.demand')]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.lemma('supply.n.02.supply').antonyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Lemma('linger.v.04.linger')]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.lemma('rush.v.01.rush').antonyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk, re, pprint\n",
    "from nltk import word_tokenize\n",
    "from urllib import request\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://news.bbc.co.uk/2/hi/health/2284783.stm'\n",
    "html = request.urlopen(url).read().decode('utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<!doctype html public \"-//W3C//DTD HTML 4.0 Transitional//EN'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html[:60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = BeautifulSoup(html, 'html.parser').get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = word_tokenize(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "111\n"
     ]
    }
   ],
   "source": [
    "for i, token in enumerate(tokens):\n",
    "    if token == 'Blondes':\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BBC', 'NEWS', '|', 'Health', '|', 'Blondes', \"'to\", 'die', 'out', 'in']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Friday',\n",
       " ',',\n",
       " '27',\n",
       " 'September',\n",
       " ',',\n",
       " '2002',\n",
       " ',',\n",
       " '11:51',\n",
       " 'GMT',\n",
       " '12:51',\n",
       " 'UK',\n",
       " 'Blondes',\n",
       " \"'to\",\n",
       " 'die',\n",
       " 'out',\n",
       " 'in',\n",
       " '200',\n",
       " \"years'\",\n",
       " 'Scientists',\n",
       " 'believe']"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens[100:120]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195\n",
      "355\n",
      "370\n",
      "400\n"
     ]
    }
   ],
   "source": [
    "for i, token in enumerate(tokens):\n",
    "    if token == 'disappear':\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The',\n",
       " 'frequency',\n",
       " 'of',\n",
       " 'blondes',\n",
       " 'may',\n",
       " 'drop',\n",
       " 'but',\n",
       " 'they',\n",
       " 'wo',\n",
       " \"n't\",\n",
       " 'disappear',\n",
       " '.',\n",
       " \"''\",\n",
       " 'See',\n",
       " 'also']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens[390:405]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokens[111:403]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Blondes',\n",
       " \"'to\",\n",
       " 'die',\n",
       " 'out',\n",
       " 'in',\n",
       " '200',\n",
       " \"years'\",\n",
       " 'Scientists',\n",
       " 'believe',\n",
       " 'the',\n",
       " 'last',\n",
       " 'blondes',\n",
       " 'will',\n",
       " 'be',\n",
       " 'in',\n",
       " 'Finland',\n",
       " 'The',\n",
       " 'last',\n",
       " 'natural',\n",
       " 'blondes',\n",
       " 'will',\n",
       " 'die',\n",
       " 'out',\n",
       " 'within',\n",
       " '200',\n",
       " 'years',\n",
       " ',',\n",
       " 'scientists',\n",
       " 'believe',\n",
       " '.',\n",
       " 'A',\n",
       " 'study',\n",
       " 'by',\n",
       " 'experts',\n",
       " 'in',\n",
       " 'Germany',\n",
       " 'suggests',\n",
       " 'people',\n",
       " 'with',\n",
       " 'blonde',\n",
       " 'hair',\n",
       " 'are',\n",
       " 'an',\n",
       " 'endangered',\n",
       " 'species',\n",
       " 'and',\n",
       " 'will',\n",
       " 'become',\n",
       " 'extinct',\n",
       " 'by',\n",
       " '2202',\n",
       " '.',\n",
       " 'Researchers',\n",
       " 'predict',\n",
       " 'the',\n",
       " 'last',\n",
       " 'truly',\n",
       " 'natural',\n",
       " 'blonde',\n",
       " 'will',\n",
       " 'be',\n",
       " 'born',\n",
       " 'in',\n",
       " 'Finland',\n",
       " '-',\n",
       " 'the',\n",
       " 'country',\n",
       " 'with',\n",
       " 'the',\n",
       " 'highest',\n",
       " 'proportion',\n",
       " 'of',\n",
       " 'blondes',\n",
       " '.',\n",
       " 'The',\n",
       " 'frequency',\n",
       " 'of',\n",
       " 'blondes',\n",
       " 'may',\n",
       " 'drop',\n",
       " 'but',\n",
       " 'they',\n",
       " 'wo',\n",
       " \"n't\",\n",
       " 'disappear',\n",
       " 'Prof',\n",
       " 'Jonathan',\n",
       " 'Rees',\n",
       " ',',\n",
       " 'University',\n",
       " 'of',\n",
       " 'Edinburgh',\n",
       " 'But',\n",
       " 'they',\n",
       " 'say',\n",
       " 'too',\n",
       " 'few',\n",
       " 'people',\n",
       " 'now',\n",
       " 'carry',\n",
       " 'the',\n",
       " 'gene',\n",
       " 'for',\n",
       " 'blondes',\n",
       " 'to',\n",
       " 'last',\n",
       " 'beyond',\n",
       " 'the',\n",
       " 'next',\n",
       " 'two',\n",
       " 'centuries',\n",
       " '.',\n",
       " 'The',\n",
       " 'problem',\n",
       " 'is',\n",
       " 'that',\n",
       " 'blonde',\n",
       " 'hair',\n",
       " 'is',\n",
       " 'caused',\n",
       " 'by',\n",
       " 'a',\n",
       " 'recessive',\n",
       " 'gene',\n",
       " '.',\n",
       " 'In',\n",
       " 'order',\n",
       " 'for',\n",
       " 'a',\n",
       " 'child',\n",
       " 'to',\n",
       " 'have',\n",
       " 'blonde',\n",
       " 'hair',\n",
       " ',',\n",
       " 'it',\n",
       " 'must',\n",
       " 'have',\n",
       " 'the',\n",
       " 'gene',\n",
       " 'on',\n",
       " 'both',\n",
       " 'sides',\n",
       " 'of',\n",
       " 'the',\n",
       " 'family',\n",
       " 'in',\n",
       " 'the',\n",
       " 'grandparents',\n",
       " \"'\",\n",
       " 'generation',\n",
       " '.',\n",
       " 'Dyed',\n",
       " 'rivals',\n",
       " 'The',\n",
       " 'researchers',\n",
       " 'also',\n",
       " 'believe',\n",
       " 'that',\n",
       " 'so-called',\n",
       " 'bottle',\n",
       " 'blondes',\n",
       " 'may',\n",
       " 'be',\n",
       " 'to',\n",
       " 'blame',\n",
       " 'for',\n",
       " 'the',\n",
       " 'demise',\n",
       " 'of',\n",
       " 'their',\n",
       " 'natural',\n",
       " 'rivals',\n",
       " '.',\n",
       " 'They',\n",
       " 'suggest',\n",
       " 'that',\n",
       " 'dyed-blondes',\n",
       " 'are',\n",
       " 'more',\n",
       " 'attractive',\n",
       " 'to',\n",
       " 'men',\n",
       " 'who',\n",
       " 'choose',\n",
       " 'them',\n",
       " 'as',\n",
       " 'partners',\n",
       " 'over',\n",
       " 'true',\n",
       " 'blondes',\n",
       " '.',\n",
       " 'Bottle-blondes',\n",
       " 'like',\n",
       " 'Ann',\n",
       " 'Widdecombe',\n",
       " 'may',\n",
       " 'be',\n",
       " 'to',\n",
       " 'blame',\n",
       " 'But',\n",
       " 'Jonathan',\n",
       " 'Rees',\n",
       " ',',\n",
       " 'professor',\n",
       " 'of',\n",
       " 'dermatology',\n",
       " 'at',\n",
       " 'the',\n",
       " 'University',\n",
       " 'of',\n",
       " 'Edinburgh',\n",
       " 'said',\n",
       " 'it',\n",
       " 'was',\n",
       " 'unlikely',\n",
       " 'blondes',\n",
       " 'would',\n",
       " 'die',\n",
       " 'out',\n",
       " 'completely',\n",
       " '.',\n",
       " '``',\n",
       " 'Genes',\n",
       " 'do',\n",
       " \"n't\",\n",
       " 'die',\n",
       " 'out',\n",
       " 'unless',\n",
       " 'there',\n",
       " 'is',\n",
       " 'a',\n",
       " 'disadvantage',\n",
       " 'of',\n",
       " 'having',\n",
       " 'that',\n",
       " 'gene',\n",
       " 'or',\n",
       " 'by',\n",
       " 'chance',\n",
       " '.',\n",
       " 'They',\n",
       " 'do',\n",
       " \"n't\",\n",
       " 'disappear',\n",
       " ',',\n",
       " \"''\",\n",
       " 'he',\n",
       " 'told',\n",
       " 'BBC',\n",
       " 'News',\n",
       " 'Online',\n",
       " '.',\n",
       " '``',\n",
       " 'The',\n",
       " 'only',\n",
       " 'reason',\n",
       " 'blondes',\n",
       " 'would',\n",
       " 'disappear',\n",
       " 'is',\n",
       " 'if',\n",
       " 'having',\n",
       " 'the',\n",
       " 'gene',\n",
       " 'was',\n",
       " 'a',\n",
       " 'disadvantage',\n",
       " 'and',\n",
       " 'I',\n",
       " 'do',\n",
       " 'not',\n",
       " 'think',\n",
       " 'that',\n",
       " 'is',\n",
       " 'the',\n",
       " 'case',\n",
       " '.',\n",
       " '``',\n",
       " 'The',\n",
       " 'frequency',\n",
       " 'of',\n",
       " 'blondes',\n",
       " 'may',\n",
       " 'drop',\n",
       " 'but',\n",
       " 'they',\n",
       " 'wo',\n",
       " \"n't\",\n",
       " 'disappear',\n",
       " '.',\n",
       " \"''\"]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = nltk.Text(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 5 of 5 matches:\n",
      "hey say too few people now carry the gene for blondes to last beyond the next \n",
      "blonde hair is caused by a recessive gene . In order for a child to have blond\n",
      " have blonde hair , it must have the gene on both sides of the family in the g\n",
      "ere is a disadvantage of having that gene or by chance . They do n't disappear\n",
      "des would disappear is if having the gene was a disadvantage and I do not thin\n"
     ]
    }
   ],
   "source": [
    "text.concordance('gene')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_corpus = nltk.corpus.words.words('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A',\n",
       " 'a',\n",
       " 'aa',\n",
       " 'aal',\n",
       " 'aalii',\n",
       " 'aam',\n",
       " 'Aani',\n",
       " 'aardvark',\n",
       " 'aardwolf',\n",
       " 'Aaron',\n",
       " 'Aaronic',\n",
       " 'Aaronical',\n",
       " 'Aaronite',\n",
       " 'Aaronitic',\n",
       " 'Aaru',\n",
       " 'Ab',\n",
       " 'aba',\n",
       " 'Ababdeh',\n",
       " 'Ababua',\n",
       " 'abac']"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_corpus[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "235886"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list=[w for w in words_corpus if w.islower()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "210687"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abaissed', 'abandoned', 'abased', 'abashed', 'abatised']"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_ed = [w for w in word_list if re.search('ed$', w)]\n",
    "words_ed[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abjectly', 'adjuster', 'dejected', 'dejectly', 'injector']"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_jt = [w for w in word_list if re.search('^..j..t..$',w)]\n",
    "words_jt[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = \"\"\"DENNIS: Listen, strange women lying in ponds distributing swords is no basis for a system of government. Supreme executive power derives from a mandate from the masses, not from some farcical aquatic ceremony.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DENNIS: Listen, strange women lying in ponds distributing swords is no basis for a system of government. Supreme executive power derives from a mandate from the masses, not from some farcical aquatic ceremony.'"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = nltk.sent_tokenize(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DENNIS: Listen, strange women lying in ponds distributing swords is no basis for a system of government.', 'Supreme executive power derives from a mandate from the masses, not from some farcical aquatic ceremony.']\n"
     ]
    }
   ],
   "source": [
    "print(sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DENNIS: Listen, strange women lying in ponds distributing swords is no basis for a system of government.\n"
     ]
    }
   ],
   "source": [
    "print(sents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Supreme executive power derives from a mandate from the masses, not from some farcical aquatic ceremony.\n"
     ]
    }
   ],
   "source": [
    "print(sents[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = word_tokenize(sents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DENNIS',\n",
       " ':',\n",
       " 'Listen',\n",
       " ',',\n",
       " 'strange',\n",
       " 'women',\n",
       " 'lying',\n",
       " 'in',\n",
       " 'ponds',\n",
       " 'distributing',\n",
       " 'swords',\n",
       " 'is',\n",
       " 'no',\n",
       " 'basis',\n",
       " 'for',\n",
       " 'a',\n",
       " 'system',\n",
       " 'of',\n",
       " 'government',\n",
       " '.']"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = word_tokenize(\"And now for something completely different.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('And', 'CC'),\n",
       " ('now', 'RB'),\n",
       " ('for', 'IN'),\n",
       " ('something', 'NN'),\n",
       " ('completely', 'RB'),\n",
       " ('different', 'JJ'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.pos_tag(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RB: adverb\n",
      "    occasionally unabatingly maddeningly adventurously professedly\n",
      "    stirringly prominently technologically magisterially predominately\n",
      "    swiftly fiscally pitilessly ...\n"
     ]
    }
   ],
   "source": [
    "nltk.help.upenn_tagset(\"RB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CC: conjunction, coordinating\n",
      "    & 'n and both but either et for less minus neither nor or plus so\n",
      "    therefore times v. versus vs. whether yet\n"
     ]
    }
   ],
   "source": [
    "nltk.help.upenn_tagset(\"CC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
